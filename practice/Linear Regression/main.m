%% Initializationclear ; close all; clc%% ==================== Part 1: Read Data ====================% Complete readData.mfprintf('Running readData ... \n');% X is independent variable, y is dependent variable[X y] = readData();% Parameter valuestheta = [0; 0];plotData(X, y);%% ==================== Part 2: Gradient Descent ====================% add 1's to X'sX = [ones(size(X,1),1), X];% Some gradient descent settingsiterations = 150;alpha = 0.001;m = length(y);[theta, J_history] = gradientDescent(X, y, theta, alpha, m, iterations);fprintf('Theta found by gradient descent:\n');fprintf('%f\n', theta);fprintf('Expected theta values (approx)\n');fprintf(' --0.0586206896552\n  1.45747126437\n\n');%disp("J history is ")%disp(J_history);% Plot the linear fithold on; % keep previous plot visibleplot(X(:,2), X*theta, '-')legend('Training data', 'Linear regression')hold off % don't overlay any more plots on this figure%% ============= Part 4: Visualizing J(theta_0, theta_1) =============plot([1:iterations], J_history);  ylabel('Cost');  xlabel('No of iterations');